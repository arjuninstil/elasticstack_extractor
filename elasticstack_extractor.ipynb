{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import ast\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import elasticsearch #version (6, 3, 1)\n",
    "from elasticsearch import helpers\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure no encode issue\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding('utf8')\n",
    "\n",
    "currentDirectory = os.getcwd()\n",
    "dataFilePath = currentDirectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFilePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticSearchExporter(object):\n",
    "    def export(self, host, indexDbName, docType, queryString, UserName, Password,\n",
    "               form='csv', queryJson=None, size=100, fields=\"all\", start=None, end=None):\n",
    "\n",
    "        es = Elasticsearch(host, http_auth=(UserName, Password),\n",
    "                           scheme=\"https\",\n",
    "                           verify_certs=False,\n",
    "                           timeout=1000)\n",
    "\n",
    "        # define query\n",
    "        query = None\n",
    "        if queryJson:\n",
    "            query = json.loads(queryJson)\n",
    "        else:\n",
    "            query = dict(\n",
    "                query=dict(\n",
    "                    query_string=dict(\n",
    "                        query=queryString\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            # query[\"sort\"] = [{\"time\":\"desc\"}]\n",
    "            query[\"size\"] = size\n",
    "\n",
    "        map_index_reference = list(es.indices.get(indexDbName))\n",
    "        map_index = map_index_reference[0]\n",
    "        map_index_reference = [i for i in map_index_reference if start <=i[-len(start):] and end >= i[-len(end):]]\n",
    "\n",
    "\n",
    "        if start == None:\n",
    "            if end == None:\n",
    "                index_check = map_index_reference\n",
    "            else:\n",
    "                index_check = map_index_reference\n",
    "\n",
    "        elif end == None:\n",
    "            index_check = map_index_reference\n",
    "\n",
    "        else:\n",
    "            start_position = map_index_reference.index(map_index_reference[0])\n",
    "            end_position = map_index_reference.index(map_index_reference[-1]) + 1\n",
    "            index_check = map_index_reference[start_position: end_position]\n",
    "            print(f'list of indexes mapped : {index_check}')\n",
    "\n",
    "\n",
    "        # Set handler to elasticsearch\n",
    "        scanResponse = helpers.scan(client=es, query=query, scroll=\"10m\", index=indexDbName, size=size, doc_type=docType, clear_scroll=False, request_timeout=3000)\n",
    "\n",
    "        counter = 0\n",
    "        # form = outputFiles.split(\".\",1)[1]\n",
    "\n",
    "        json_file = []\n",
    "        for row in scanResponse:\n",
    "            #if counter <= 10000:\n",
    "               \n",
    "            if row['_index'] in index_check:\n",
    "                if fields == \"all\":\n",
    "                    json_file.append(row)\n",
    "\n",
    "                else:\n",
    "                    json_file.append(row['_source'][fields])\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "            else:\n",
    "                counter = counter\n",
    "                    \n",
    "            #else:\n",
    "             #   break\n",
    "\n",
    "        if form == 'df':\n",
    "            data_frame = pd.DataFrame(json_file)\n",
    "\n",
    "            #for c in data_frame.columns:\n",
    "                #data_frame[c] = data_frame[c].map(lambda i : ast.literal_eval(i))\n",
    "\n",
    "            col = list(data_frame.columns)\n",
    "\n",
    "            d = []\n",
    "            for c in col:\n",
    "                if type(data_frame.iloc[1][c]) == dict:\n",
    "                    d.append(c)\n",
    "\n",
    "            for i in d:\n",
    "                df1 = json_normalize(data_frame[i])\n",
    "                data_frame = pd.concat([data_frame, df1], axis=1, join_axes=[df1.index])\n",
    "\n",
    "            data_frame.drop(d, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "            print('%s lines was expotred' % (counter))\n",
    "            return data_frame\n",
    "\n",
    "\n",
    "        if form == 'json':\n",
    "            print('%s lines was expotred' % (counter))\n",
    "            return json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exporter = ElasticSearchExporter()\n",
    "exporter.export(form = '<format>', #df or json\n",
    "                host = '<hostname>', #e.g. : 'https://msb-elk-int.de050.corpintra.net:9200'\n",
    "                UserName = '<user_name>',\n",
    "                Password = '<password>',\n",
    "                indexDbName ='<indexname>', #e.g. : 'it-ocs_msb_prd-tsb-te1500ac-process-v1-2019.01.*'\n",
    "                start = '<index_start>', #e.g. : '15' or '01.15' for moth and date\n",
    "                end = '<index_end>', #e.g. : '16' or '01.16' for month and date\n",
    "                docType = '<doc_type>', #e.g. : 'PROCESS'\n",
    "                queryString = None,\n",
    "                queryJson = '<query>', #'{\"query\": {\"bool\": {\"should\": [{\"match\": {\"Payload.CYCLETIME.RobotName\":\"UB64_150RB_100\"}},{\"match\": {\"Payload.CYCLETIME.RobotName\":\"UB64_150RB_200\"}}]}}}\n",
    "                size = 1000,\n",
    "                fields = \"all\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
